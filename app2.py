import streamlit as st
import google.generativeai as genai
import os
import time
import datetime
import qrcode
import json
from PIL import Image
from io import BytesIO
from google.api_core.exceptions import ResourceExhausted

# ==========================================
#  è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
st.set_page_config(page_title="AIå•è¨º - é‚£é ˆä¹ƒã‚¢ã‚¤", page_icon="ğŸ¥", layout="wide") 

# APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except Exception:
    st.error("APIã‚­ãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: .streamlit/secrets.toml (ã¾ãŸã¯Cloudã®Secrets) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ä»Šæ—¥ã®æ—¥ä»˜
today_str = datetime.date.today().strftime("%Y/%m/%d")

# ==========================================
#  ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
# ==========================================
if "patient_data" not in st.session_state:
    st.session_state.patient_data = None 

if "messages" not in st.session_state:
    st.session_state.messages = []

if "audio_key" not in st.session_state:
    st.session_state.audio_key = 0

# ==========================================
#  é–¢æ•°å®šç¾©ï¼šæ™‚é–“å¸¯ã”ã¨ã®æŒ¨æ‹¶
# ==========================================
def get_time_based_greeting():
    hour = datetime.datetime.now().hour
    if hour < 10:
        return "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™"
    elif hour < 18:
        return "ã“ã‚“ã«ã¡ã¯"
    else:
        return "ã“ã‚“ã°ã‚“ã¯"

# ==========================================
#  é–¢æ•°å®šç¾©ï¼šQRã‚³ãƒ¼ãƒ‰ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢
# ==========================================
def format_text_for_qr(text):
    lines = text.split('\n')
    new_lines = []
    
    for line in lines:
        if "æ°åï¼š" in line and "ç”Ÿ)" in line:
            continue
        
        clean_line = line.replace("â–  S (Subjective)", "ã€Sã€‘")
        clean_line = clean_line.replace("â–  O (Objective)", "ã€Oã€‘")
        clean_line = clean_line.replace("â–  æ‚£è€…å¸Œæœ›", "ã€Pã€‘")
        clean_line = clean_line.replace("â–  Plan", "ã€Pã€‘")
        
        if "---" in clean_line:
            continue
            
        new_lines.append(clean_line)
    
    formatted_text = "\r\n".join(new_lines)
    
    while "\r\n\r\n\r\n" in formatted_text:
        formatted_text = formatted_text.replace("\r\n\r\n\r\n", "\r\n\r\n")
        
    return formatted_text.strip()

# ==========================================
#  é–¢æ•°å®šç¾©ï¼šç”»åƒã‹ã‚‰å€‹äººæƒ…å ±ã‚’æŠ½å‡º
# ==========================================
def extract_patient_info(image_data):
    model = genai.GenerativeModel('gemini-2.5-flash')
    img = Image.open(image_data)
    prompt = """
    ã“ã®èº«åˆ†è¨¼ï¼ˆãƒã‚¤ãƒŠãƒ³ãƒãƒ¼ã‚«ãƒ¼ãƒ‰ç­‰ï¼‰ã®ç”»åƒã‹ã‚‰ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚
    1. æ°åï¼ˆæ¼¢å­—ï¼‰
    2. ç”Ÿå¹´æœˆæ—¥ï¼ˆè¥¿æš¦yyyyå¹´mmæœˆddæ—¥å½¢å¼ã«å¤‰æ›ï¼‰
    
    å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§è¡Œã£ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªæ–‡ç« ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚
    ```json
    {
        "name": "æ°å",
        "dob": "yyyyå¹´mmæœˆddæ—¥"
    }
    ```
    """
    try:
        response = model.generate_content([prompt, img])
        text = response.text.strip()
        json_str = text.replace("```json", "").replace("```", "").strip()
        data = json.loads(json_str)
        return data
    except Exception as e:
        st.error(f"èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
#  é–¢æ•°å®šç¾©ï¼šå•è¨ºAIï¼ˆãƒãƒ£ãƒƒãƒˆï¼‰
# ==========================================
def generate_response_with_fallback(chat_history, patient_name, patient_dob):
    models_to_try = [
        "gemini-2.5-flash-lite",
        "gemini-2.5-flash",
        "gemini-3-flash-preview",
        "gemini-2.0-flash",
    ]
    
    greeting = get_time_based_greeting()

    DYNAMIC_SYSTEM_PROMPT = f"""
    ã‚ãªãŸã¯æ•´å½¢å¤–ç§‘ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã®AIå•è¨ºæ‹…å½“ã€Œé‚£é ˆä¹ƒã‚¢ã‚¤ï¼ˆãªã™ã®ã‚ã„ï¼‰ã€ã§ã™ã€‚
    ä»¥ä¸‹ã®ã€å•è¨ºãƒ•ãƒ­ãƒ¼ã€‘ã«å¾“ã£ã¦ã€æ‚£è€…ã¨å¯¾è©±ã—ã€æƒ…å ±ã‚’åé›†ã—ã¦ãã ã•ã„ã€‚
    **æœ¬æ—¥ã®æ—¥ä»˜ã¯ {today_str} ã§ã™ã€‚**

    ã€é‡è¦ï¼šæ‚£è€…æƒ…å ±ã€‘
    * **æ°å:** {patient_name}
    * **ç”Ÿå¹´æœˆæ—¥:** {patient_dob}
    ã“ã®æƒ…å ±ã¯å–å¾—æ¸ˆã¿ã§ã™ã€‚ã€Œ2. æ‚£è€…æƒ…å ±ã€ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚

    ã€å•è¨ºãƒ•ãƒ­ãƒ¼ã€‘
    1. æŒ¨æ‹¶ï¼†åˆè¨ºç¢ºèªï¼š
       â€»æœ€åˆã®ç™ºè¨€ã§ã€Œ{patient_name}ã•ã‚“ã€{greeting}ã€‚é‚£é ˆä¹ƒã‚ã„ã§ã™ã€‚æœ¬æ—¥ã®å•è¨ºã‚’æ‹…å½“ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„è‡´ã—ã¾ã™ã€‚å½“é™¢ã¸ã®ã”æ¥é™¢ã¯åˆã‚ã¦ã§ã™ã‹ï¼Ÿã€ã¨æŒ¨æ‹¶ã¨è³ªå•ã‚’ã¾ã¨ã‚ã¦è¡Œã£ã¦ã„ã‚‹çŠ¶æ…‹ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¾ã™ã€‚
       **ã—ãŸãŒã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆæ‚£è€…ï¼‰ã‹ã‚‰ã®æœ€åˆã®è¿”ç­”ã¯ã€Œåˆè¨ºã‹ã©ã†ã‹ã€ã®å›ç­”ã«ãªã‚Šã¾ã™ã€‚**
    
    2. (ã‚¹ã‚­ãƒƒãƒ—)
    3. (ã‚¹ã‚­ãƒƒãƒ—)
    4. åˆè¨ºç¢ºèªã®ç¶šãï¼š
       ã‚‚ã—æ‚£è€…ã®è¿”ç­”ãŒåˆè¨ºã‹ã©ã†ã‹ã‚ã‹ã‚‰ãªã„å ´åˆã¯èãç›´ã™ã€‚ã‚ã‹ã£ãŸå ´åˆã¯æ¬¡ã«é€²ã‚€ã€‚
       
    5. (å†è¨ºã®å ´åˆã®ã¿)ï¼šåŒ»å¸«åã®ç¢ºèª
    6. æ¥é™¢ç†ç”±ï¼šã€Œæœ¬æ—¥ã¯ã©ã†ã„ã£ãŸç—‡çŠ¶ã§ã”æ¥é™¢ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿã€
    7. ä¸»è¨´ã®ç¢ºèªï¼šèãå–ã£ãŸç—‡çŠ¶ã‚’ç®‡æ¡æ›¸ãã§ç¢ºèª
    8. è©³ç´°è´å–ï¼šç™ºç—‡èµ·ç‚¹ã€åŸå› ã€å¢—æ‚ªå› å­ãªã©ã‚’è©³ã—ã
    9. ã¾ã¨ã‚ç¢ºèª
    10. ç”»åƒæ¤œæŸ»ã®å¸Œæœ›
    11. éª¨ç²—é¬†ç—‡æ¤œæŸ»ã®å¸Œæœ›
    12. åŒ»å¸«å¸Œæœ›
    13. çµ‚äº†æ¡ˆå†…

    ã€æœ€çµ‚å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å³æ ¼ãªãƒ«ãƒ¼ãƒ«ã€‘
    ä¼šè©±çµ‚äº†å¾Œã€ä»¥ä¸‹ã®SOAPå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚Markdownã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ä½¿ç”¨ã›ãšã€ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚

    ### 1. æ—¥ä»˜è¨˜è¼‰ã®çµ¶å¯¾ãƒ«ãƒ¼ãƒ«
    ã™ã¹ã¦ã®ç›¸å¯¾çš„ãªæ—¥ä»˜è¡¨ç¾ã¯ã€**ã€Œå‡ºåŠ›ã‚’è¡Œã£ãŸå½“æ—¥ï¼ˆ{today_str}ï¼‰ã€ã‚’åŸºæº–æ—¥**ã¨ã—ã¦ã€ä»¥ä¸‹ã®å½¢å¼ã§å…·ä½“çš„ãªæ—¥ä»˜ã«å¤‰æ›ã—ã¦è¨˜è¼‰ã™ã‚‹ã“ã¨ã€‚
    * **åŸºæº–:** æœ¬æ—¥ï¼ˆ{today_str}ï¼‰
    * **æ˜¨æ—¥:** æ­£ç¢ºãªæ—¥ä»˜ã§è¨˜è¼‰ï¼ˆä¾‹: yyyy/mm/ddï¼‰
    * **2é€±é–“å‰:** 14æ—¥å‰ã‚’è¨ˆç®—ã—ã¦ã€Œyyyy/mm/ddé ƒã€ã¨ã™ã‚‹
    * **1ãƒ¶æœˆå‰:** æœˆå˜ä½ã®å ´åˆã¯ã€Œä¸Šæ—¬/ä¸­æ—¬/ä¸‹æ—¬ã€ã§è¡¨ç¾
    * **åŠå¹´ä»¥ä¸Šå‰:** ã€Œyyyy/mmæœˆä¸‹æ—¬é ƒã€ã¾ãŸã¯å¹´å˜ä½ã®çµŒéã¨ã—ã¦è¨˜è¼‰ã€‚
    * **ç¦æ­¢äº‹é …:** ã€Œ1é€±é–“å‰ã€ã€Œæ•°æ—¥å‰ã€ã€Œæ˜¨æ—¥ã€ãªã©ã®ç›¸å¯¾è¡¨ç¾ã‚’ãã®ã¾ã¾å‡ºåŠ›ã«æ®‹ã•ãªã„ã“ã¨ã€‚ã“ã‚Œã‚‰ã¯å¿…ãšæ—¥ä»˜ã«å¤‰æ›ã™ã‚‹ã“ã¨ã€‚

    ### 2. å‡ºåŠ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    ---
    â–  S (Subjective)
    æ°åï¼š{patient_name} ({patient_dob}ç”Ÿ)
    ä¸»è¨´ï¼š
    #1. (åè©ã¾ãŸã¯ä½“è¨€æ­¢ã‚ã§ç°¡æ½”ã«è¨˜è¼‰)
    #2. (åè©ã¾ãŸã¯ä½“è¨€æ­¢ã‚ã§ç°¡æ½”ã«è¨˜è¼‰)
    (â€»å„é …ç›®ã®é–“ã«ã¯ç©ºè¡Œã‚’å…¥ã‚Œãšè©°ã‚ã‚‹ã“ã¨)

    ç¾ç—…æ­´ï¼š
    (ç™ºç—‡èµ·ç‚¹ã€åŸå› ã€çµŒéãªã©ã‚’è¨˜è¼‰ã€‚æ—¥ä»˜ã¯å¿…ãšyyyy/mm/ddå½¢å¼)
    (â€»æœ€çµ‚è¡Œã¯å¿…ãšä»¥ä¸‹ã®3ã¤ã®ã†ã¡ã„ãšã‚Œã‹1æ–‡ã§ç· ã‚ããã‚‹)
    1. {today_str} ã€€ç—‡çŠ¶ãŒæŒç¶šã—ã¦ã„ã‚‹ãŸã‚å½“é™¢ã‚’å—è¨º
    2. {today_str} ã€€ç—‡çŠ¶ãŒæ”¹å–„ã—ãªã„ãŸã‚å½“é™¢ã‚’å—è¨º
    3. {today_str} ã€€ç—‡çŠ¶ãŒæ‚ªåŒ–ã—ã¦ããŸãŸã‚å½“é™¢ã‚’å—è¨º

    â–  O (Objective)
    (å•è¨ºã§å¾—ã‚‰ã‚ŒãŸç—‡çŠ¶ã®è£œè¶³äº‹é …ãŒã‚ã‚Œã°è¨˜è¼‰ã€‚ãªã‘ã‚Œã°ã€Œç‰¹è¨˜ãªã—ã€)

    â–  æ‚£è€…å¸Œæœ›
    - CTã€MRIã§ã®ç²¾æŸ»ï¼š (å›ç­”å†…å®¹)
    - éª¨ç²—é¬†ç—‡ã®æ¤œæŸ»ï¼š (å¸Œæœ›ã™ã‚‹ / ã—ãªã„)
    - å¸Œæœ›ã®å…ˆç”Ÿï¼š (åŒ»å¸«å / ç‰¹ã«ãªã—)
    ---
    """
    
    gemini_history = []
    for msg in chat_history:
        role = "model" if msg["role"] == "assistant" else "user"
        gemini_history.append({"role": role, "parts": [msg["content"]]})

    for model_name in models_to_try:
        try:
            model = genai.GenerativeModel(model_name, system_instruction=DYNAMIC_SYSTEM_PROMPT)
            if len(gemini_history) > 1:
                chat = model.start_chat(history=gemini_history[:-1])
                response = chat.send_message(gemini_history[-1]["parts"][0])
            else:
                chat = model.start_chat(history=[])
                response = chat.send_message(gemini_history[-1]["parts"][0])
            return response.text
        except Exception:
            time.sleep(1)
            continue
    
    raise Exception("æ··é›‘ã®ãŸã‚å¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

# ==========================================
#  é–¢æ•°å®šç¾©ï¼šéŸ³å£°èªè­˜
# ==========================================
def transcribe_audio_with_fallback(audio_file_path):
    models_to_try = ["gemini-2.5-flash-lite", "gemini-2.5-flash", "gemini-2.0-flash"]
    audio_file = genai.upload_file(path=audio_file_path)
    for model_name in models_to_try:
        try:
            model = genai.GenerativeModel(model_name)
            res = model.generate_content(["ã“ã®éŸ³å£°ã‚’æ—¥æœ¬èªã§æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚", audio_file])
            return res.text.strip()
        except:
             continue
    return ""

# ==========================================
#  é–¢æ•°å®šç¾©ï¼šQRã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
# ==========================================
def generate_qr_image(text):
    cleaned_text = format_text_for_qr(text)
    qr = qrcode.QRCode(box_size=10, border=4)
    qr.add_data(cleaned_text)
    qr.make(fit=True)
    img = qr.make_image(fill_color="black", back_color="white")
    buf = BytesIO()
    img.save(buf)
    return buf

# ==========================================
#  ãƒ¡ã‚¤ãƒ³ç”»é¢æ§‹æˆ
# ==========================================
st.title("ğŸ¥ æ•´å½¢å¤–ç§‘ AIå•è¨º")

# ------------------------------------------
#  Phase 1: å—ä»˜ãƒ¢ãƒ¼ãƒ‰
# ------------------------------------------
if st.session_state.patient_data is None:
    st.info("ã€å—ä»˜ã€‘æ‚£è€…æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    tab1, tab2 = st.tabs(["ğŸ“· ã‚«ãƒ¡ãƒ©ã§èª­å–", "âŒ¨ï¸ æ‰‹å‹•ã§å…¥åŠ›"])
    
    # â˜… ã“ã“ã§ã® initial_msg ã‚’å¤‰æ›´ã—ã¾ã—ãŸï¼
    with tab1:
        img_file = st.camera_input("ã‚«ãƒ¼ãƒ‰æ’®å½±")
        if img_file:
            with st.spinner("èª­ã¿å–ã‚Šä¸­..."):
                extracted = extract_patient_info(img_file)
                if extracted:
                    st.session_state.patient_data = extracted
                    greeting = get_time_based_greeting()
                    # æŒ¨æ‹¶ ï¼‹ åˆè¨ºè³ªå• ã‚’ã‚»ãƒƒãƒˆã«ã™ã‚‹
                    initial_msg = f"{extracted['name']}ã•ã‚“ã€{greeting}ã€‚é‚£é ˆä¹ƒã‚ã„ã§ã™ã€‚æœ¬æ—¥ã®å•è¨ºã‚’æ‹…å½“ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„è‡´ã—ã¾ã™ã€‚\n\næ—©é€Ÿã§ã™ãŒã€å½“é™¢ã¸ã®ã”æ¥é™¢ã¯åˆã‚ã¦ã§ã™ã‹ï¼Ÿ"
                    st.session_state.messages = [{"role": "assistant", "content": initial_msg}]
                    st.success("æˆåŠŸï¼")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("èª­ã¿å–ã‚Šå¤±æ•—")

    with tab2:
        with st.form("manual_input_form"):
            input_name = st.text_input("æ°å")
            default_date = datetime.date(1980, 1, 1)
            input_dob = st.date_input("ç”Ÿå¹´æœˆæ—¥", value=default_date, min_value=datetime.date(1900, 1, 1))
            if st.form_submit_button("è¨ºå¯Ÿé–‹å§‹"):
                if input_name:
                    dob_str = input_dob.strftime("%Yå¹´%mæœˆ%dæ—¥")
                    st.session_state.patient_data = {"name": input_name, "dob": dob_str}
                    greeting = get_time_based_greeting()
                    # æŒ¨æ‹¶ ï¼‹ åˆè¨ºè³ªå• ã‚’ã‚»ãƒƒãƒˆã«ã™ã‚‹
                    initial_msg = f"{input_name}ã•ã‚“ã€{greeting}ã€‚é‚£é ˆä¹ƒã‚ã„ã§ã™ã€‚æœ¬æ—¥ã®å•è¨ºã‚’æ‹…å½“ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„è‡´ã—ã¾ã™ã€‚\n\næ—©é€Ÿã§ã™ãŒã€å½“é™¢ã¸ã®ã”æ¥é™¢ã¯åˆã‚ã¦ã§ã™ã‹ï¼Ÿ"
                    st.session_state.messages = [{"role": "assistant", "content": initial_msg}]
                    st.rerun()

# ------------------------------------------
#  Phase 2: å•è¨ºãƒ¢ãƒ¼ãƒ‰
# ------------------------------------------
else:
    p_name = st.session_state.patient_data['name']
    p_dob = st.session_state.patient_data['dob']
    
    st.caption(f"æ‹…å½“ï¼šé‚£é ˆä¹ƒã‚¢ã‚¤ (Date: {today_str}) | æ‚£è€…ï¼š{p_name} æ§˜ ({p_dob})")
    
    if st.button("è¨ºå¯Ÿçµ‚äº† / æ¬¡ã®æ‚£è€…ã¸"):
        st.session_state.patient_data = None
        st.session_state.messages = []
        st.rerun()

    for msg in st.session_state.messages:
        if msg["role"] == "assistant":
            with st.chat_message("assistant", avatar="ğŸ‘©â€âš•ï¸"):
                if "â–  S (Subjective)" in msg["content"]:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(msg["content"])
                    with col2:
                        qr_image = generate_qr_image(msg["content"])
                        st.image(qr_image, caption="é›»å­ã‚«ãƒ«ãƒ†è»¢é€ç”¨QR", use_container_width=True)
                else:
                    st.markdown(msg["content"])
        else:
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.markdown(msg["content"])

    audio_value = st.audio_input("ãƒã‚¤ã‚¯ã§å›ç­”", key=f"audio_{st.session_state.audio_key}")
    user_text_input = st.chat_input("ãƒ†ã‚­ã‚¹ãƒˆã§å›ç­”")

    user_input = None
    if audio_value:
        with st.spinner("èªè­˜ä¸­..."):
            temp = f"temp_{int(time.time())}.wav"
            with open(temp, "wb") as f: f.write(audio_value.getvalue())
            try: user_input = transcribe_audio_with_fallback(temp)
            except: pass
            if os.path.exists(temp): os.remove(temp)
            st.session_state.audio_key += 1
    elif user_text_input:
        user_input = user_text_input

    if user_input and user_input != "":
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(user_input)
        try:
            with st.spinner("è€ƒæ¡ˆä¸­..."):
                ai_text = generate_response_with_fallback(st.session_state.messages, p_name, p_dob)
            st.session_state.messages.append({"role": "assistant", "content": ai_text})
            st.rerun()
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            st.rerun()
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

