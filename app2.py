import streamlit as st
import google.generativeai as genai
import os
import time
import datetime
import qrcode
import json
from PIL import Image
from io import BytesIO
from google.api_core.exceptions import ResourceExhausted

# ==========================================
#  è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
st.set_page_config(page_title="AIå•è¨º - é‚£é ˆä¹ƒã‚¢ã‚¤", page_icon="ğŸ¥", layout="wide") 

try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except Exception:
    st.error("APIã‚­ãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: .streamlit/secrets.toml (ã¾ãŸã¯Cloudã®Secrets) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

today_str = datetime.date.today().strftime("%Y/%m/%d")

# ==========================================
#  ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
# ==========================================
if "patient_data" not in st.session_state:
    st.session_state.patient_data = None 
if "messages" not in st.session_state:
    st.session_state.messages = []
if "audio_key" not in st.session_state:
    st.session_state.audio_key = 0
if "interview_state" not in st.session_state:
    st.session_state.interview_state = "chat" # chat, form, complete

# ==========================================
#  é–¢æ•°å®šç¾©ç¾¤
# ==========================================
def get_time_based_greeting():
    hour = datetime.datetime.now().hour
    if hour < 10: return "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™"
    elif hour < 18: return "ã“ã‚“ã«ã¡ã¯"
    else: return "ã“ã‚“ã°ã‚“ã¯"

def format_text_for_qr(text):
    lines = text.split('\n')
    new_lines = []
    for line in lines:
        if "æ°åï¼š" in line and "ç”Ÿ)" in line: continue
        clean_line = line.replace("â–  S (Subjective)", "ã€Sã€‘")
        clean_line = clean_line.replace("â–  O (Objective)", "ã€Oã€‘")
        clean_line = clean_line.replace("â–  æ‚£è€…å¸Œæœ›", "ã€Pã€‘")
        clean_line = clean_line.replace("â–  Plan", "ã€Pã€‘")
        if "---" in clean_line: continue
        new_lines.append(clean_line)
    formatted_text = "\r\n".join(new_lines)
    while "\r\n\r\n\r\n" in formatted_text:
        formatted_text = formatted_text.replace("\r\n\r\n\r\n", "\r\n\r\n")
    return formatted_text.strip()

def extract_patient_info(image_data):
    model = genai.GenerativeModel('gemini-2.5-flash')
    img = Image.open(image_data)
    prompt = """
    ã“ã®èº«åˆ†è¨¼ï¼ˆãƒã‚¤ãƒŠãƒ³ãƒãƒ¼ã‚«ãƒ¼ãƒ‰ç­‰ï¼‰ã®ç”»åƒã‹ã‚‰ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚
    1. æ°åï¼ˆæ¼¢å­—ï¼‰
    2. ç”Ÿå¹´æœˆæ—¥ï¼ˆè¥¿æš¦yyyyå¹´mmæœˆddæ—¥å½¢å¼ã«å¤‰æ›ï¼‰
    å‡ºåŠ›ã¯JSONå½¢å¼ã®ã¿ã§è¡Œã£ã¦ãã ã•ã„ã€‚
    ```json
    { "name": "æ°å", "dob": "yyyyå¹´mmæœˆddæ—¥" }
    ```
    """
    try:
        response = model.generate_content([prompt, img])
        text = response.text.strip()
        json_str = text.replace("```json", "").replace("```", "").strip()
        return json.loads(json_str)
    except:
        return None

def transcribe_audio_with_fallback(audio_file_path):
    models = ["gemini-2.5-flash-lite", "gemini-2.5-flash", "gemini-2.0-flash"]
    audio_file = genai.upload_file(path=audio_file_path)
    for m in models:
        try:
            model = genai.GenerativeModel(m)
            res = model.generate_content(["ã“ã®éŸ³å£°ã‚’æ—¥æœ¬èªã§æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚", audio_file])
            return res.text.strip()
        except: continue
    return ""

def generate_qr_image(text):
    cleaned_text = format_text_for_qr(text)
    qr = qrcode.QRCode(box_size=10, border=4)
    qr.add_data(cleaned_text)
    qr.make(fit=True)
    img = qr.make_image(fill_color="black", back_color="white")
    buf = BytesIO()
    img.save(buf)
    return buf

# ==========================================
#  AIå¿œç­”ç”Ÿæˆï¼ˆãƒãƒ£ãƒƒãƒˆç”¨ï¼‰
# ==========================================
def generate_chat_response(chat_history, patient_name, patient_dob):
    models = ["gemini-2.5-flash-lite", "gemini-2.5-flash", "gemini-3-flash-preview"]
    greeting = get_time_based_greeting()

    SYSTEM_PROMPT = f"""
    ã‚ãªãŸã¯æ•´å½¢å¤–ç§‘ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã®AIå•è¨ºæ‹…å½“ã€Œé‚£é ˆä¹ƒã‚¢ã‚¤ã€ã§ã™ã€‚
    æœ¬æ—¥ã¯ {today_str} ã§ã™ã€‚
    æ‚£è€…ï¼š{patient_name} ({patient_dob}) â€»å–å¾—æ¸ˆã¿

    ã€ã‚¿ã‚¹ã‚¯ã€‘
    æ‚£è€…ã®ä¸»è¨´ã€ç™ºç—‡æ™‚æœŸã€åŸå› ã€çµŒéï¼ˆç¾ç—…æ­´ï¼‰ã‚’è´å–ã—ã¦ãã ã•ã„ã€‚
    
    ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
    1. æŒ¨æ‹¶ï¼†åˆè¨ºç¢ºèªï¼šã€Œ{patient_name}ã•ã‚“ã€{greeting}ã€‚é‚£é ˆä¹ƒã‚ã„ã§ã™...å½“é™¢ã¸ã®ã”æ¥é™¢ã¯åˆã‚ã¦ã§ã™ã‹ï¼Ÿã€ã‹ã‚‰é–‹å§‹ã€‚
    2. ç—‡çŠ¶ã®è´å–ãŒååˆ†ã«çµ‚ã‚ã£ãŸã‚‰ã€**ã“ã‚Œä»¥ä¸Šè³ªå•ã›ãš**ã€ä»¥ä¸‹ã®çµ‚äº†åˆå›³ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
       å‡ºåŠ›ï¼š <END_OF_INTERVIEW>
    3. **ã¾ã SOAPã¾ã¨ã‚ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚**
    4. ç”»åƒæ¤œæŸ»ã€éª¨ç²—é¬†ç—‡æ¤œæŸ»ã€åŒ»å¸«å¸Œæœ›ã«ã¤ã„ã¦ã¯**è³ªå•ã—ãªã„ã§ãã ã•ã„**ï¼ˆå¾Œã§ç”»é¢ã§å…¥åŠ›ã—ã¾ã™ï¼‰ã€‚

    ã€ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«ã€‘
    ä¸å¯§ã‹ã¤ç°¡æ½”ã«ã€‚1å›ã®ç™ºè¨€ã§è³ªå•ã¯1ã¤ã¾ã§ã€‚
    """
    
    gemini_history = [{"role": "model" if m["role"]=="assistant" else "user", "parts": [m["content"]]} for m in chat_history]

    for m_name in models:
        try:
            model = genai.GenerativeModel(m_name, system_instruction=SYSTEM_PROMPT)
            chat = model.start_chat(history=gemini_history[:-1] if len(gemini_history)>1 else [])
            response = chat.send_message(gemini_history[-1]["parts"][0])
            return response.text
        except: continue
    raise Exception("å¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸ")

# ==========================================
#  æœ€çµ‚SOAPä½œæˆ
# ==========================================
def generate_final_soap(chat_history, patient_name, patient_dob, selection_data):
    models = ["gemini-3-flash-preview", "gemini-2.5-flash"]
    
    plan_text = f"""
    - ç”»åƒæ¤œæŸ»å¸Œæœ›: {selection_data['image_exam']}
    - éª¨ç²—é¬†ç—‡æ¤œæŸ»: {selection_data['osteo_exam']}
    - åŒ»å¸«å¸Œæœ›: {selection_data['doctor']}
    """

    PROMPT = f"""
    ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’ã‚‚ã¨ã«ã€æ•´å½¢å¤–ç§‘ã®é›»å­ã‚«ãƒ«ãƒ†ç”¨SOAPï¼ˆSéƒ¨åˆ†ï¼‰ã‚’ä½œæˆã—ã€
    æœ€å¾Œã«ä»¥ä¸‹ã®æ‚£è€…å¸Œæœ›æƒ…å ±ï¼ˆPéƒ¨åˆ†ï¼‰ã‚’çµåˆã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    ã€æ‚£è€…å¸Œæœ›æƒ…å ±ã€‘
    {plan_text}

    ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å³æ ¼ãªãƒ«ãƒ¼ãƒ«ã€‘
    Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ä½¿ç”¨ã—ãªã„ã“ã¨ã€‚

    ### 1. æ—¥ä»˜è¨˜è¼‰ã®çµ¶å¯¾ãƒ«ãƒ¼ãƒ« (åŸºæº–æ—¥: {today_str})
    * ç›¸å¯¾æ—¥ä»˜ï¼ˆæ˜¨æ—¥ã€2é€±é–“å‰ãªã©ï¼‰ã¯å¿…ãš {today_str} ã‹ã‚‰é€†ç®—ã—ãŸã€Œyyyy/mm/ddã€å½¢å¼ã«å¤‰æ›ã€‚
    * ã€Œ1é€±é–“å‰ã€ã€Œæ˜¨æ—¥ã€ãªã©ã®è¨€è‘‰ã¯ç¦æ­¢ã€‚
    * 1ãƒ¶æœˆå‰â†’ã€Œyyyy/mmæœˆä¸Šæ—¬/ä¸­æ—¬/ä¸‹æ—¬ã€
    * åŠå¹´ä»¥ä¸Šå‰â†’ã€Œyyyy/mmæœˆä¸‹æ—¬é ƒã€ã¾ãŸã¯å¹´å˜ä½

    ### 2. ç¾ç—…æ­´ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆä¸»è¨´ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
    #1. (ä¸»è¨´)
    yyyy/mm/dd (çµŒéè¨˜è¿°...)
    yyyy/mm/dd (å—è¨ºç†ç”±...)
    
    (ç©ºè¡Œ)

    #2. (ä¸»è¨´)
    yyyy/mm/dd (çµŒéè¨˜è¿°...)
    ...

    ### å‡ºåŠ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    ---
    â–  S (Subjective)
    æ°åï¼š{patient_name} ({patient_dob}ç”Ÿ)
    ä¸»è¨´ï¼š
    #1. (ä½“è¨€æ­¢ã‚)
    #2. (ä½“è¨€æ­¢ã‚)

    ç¾ç—…æ­´ï¼š
    (ä¸Šè¨˜ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«å¾“ã£ã¦è¨˜è¿°)
    (â€»å„ä¸»è¨´ãƒ–ãƒ­ãƒƒã‚¯ã®æœ€çµ‚è¡Œã¯å¿…ãšä»¥ä¸‹ã®ã„ãšã‚Œã‹ã§ç· ã‚ã‚‹)
    1. {today_str} ã€€ç—‡çŠ¶ãŒæŒç¶šã—ã¦ã„ã‚‹ãŸã‚å½“é™¢ã‚’å—è¨º
    2. {today_str} ã€€ç—‡çŠ¶ãŒæ”¹å–„ã—ãªã„ãŸã‚å½“é™¢ã‚’å—è¨º
    3. {today_str} ã€€ç—‡çŠ¶ãŒæ‚ªåŒ–ã—ã¦ããŸãŸã‚å½“é™¢ã‚’å—è¨º

    â–  O (Objective)
    (ä¼šè©±ã‹ã‚‰åˆ†ã‹ã‚‹ç‰¹è¨˜ã‚ã‚Œã°è¨˜è¼‰ã€ãªã‘ã‚Œã°ã€Œç‰¹è¨˜ãªã—ã€)

    â–  æ‚£è€…å¸Œæœ›
    {plan_text}
    ---
    """
    
    conversation_text = "\n".join([f"{m['role']}: {m['content']}" for m in chat_history])
    
    for m_name in models:
        try:
            model = genai.GenerativeModel(m_name)
            response = model.generate_content([PROMPT, conversation_text])
            return response.text
        except: continue
    return "ã‚¨ãƒ©ãƒ¼ï¼šã‚«ãƒ«ãƒ†ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ"

# ==========================================
#  ãƒ¡ã‚¤ãƒ³ç”»é¢æ§‹æˆ
# ==========================================
st.title("ğŸ¥ æ•´å½¢å¤–ç§‘ AIå•è¨º")

# --- 1. å—ä»˜ãƒ•ã‚§ãƒ¼ã‚º ---
if st.session_state.patient_data is None:
    st.info("ã€å—ä»˜ã€‘æ‚£è€…æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    tab1, tab2 = st.tabs(["ğŸ“· ã‚«ãƒ¡ãƒ©ã§èª­å–", "âŒ¨ï¸ æ‰‹å‹•ã§å…¥åŠ›"])
    
    with tab1:
        img_file = st.camera_input("ã‚«ãƒ¼ãƒ‰æ’®å½±")
        if img_file:
            with st.spinner("èª­ã¿å–ã‚Šä¸­..."):
                extracted = extract_patient_info(img_file)
                if extracted:
                    st.session_state.patient_data = extracted
                    st.session_state.messages = []
                    greeting = get_time_based_greeting()
                    initial_msg = f"{extracted['name']}ã•ã‚“ã€{greeting}ã€‚é‚£é ˆä¹ƒã‚ã„ã§ã™ã€‚æœ¬æ—¥ã®å•è¨ºã‚’æ‹…å½“ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„è‡´ã—ã¾ã™ã€‚\n\næ—©é€Ÿã§ã™ãŒã€å½“é™¢ã¸ã®ã”æ¥é™¢ã¯åˆã‚ã¦ã§ã™ã‹ï¼Ÿ"
                    st.session_state.messages.append({"role": "assistant", "content": initial_msg})
                    st.rerun()

    with tab2:
        with st.form("manual"):
            name = st.text_input("æ°å")
            dob = st.date_input("ç”Ÿå¹´æœˆæ—¥", value=datetime.date(1980,1,1), min_value=datetime.date(1900,1,1))
            if st.form_submit_button("è¨ºå¯Ÿé–‹å§‹"):
                dob_str = dob.strftime("%Yå¹´%mæœˆ%dæ—¥")
                st.session_state.patient_data = {"name": name, "dob": dob_str}
                st.session_state.messages = []
                greeting = get_time_based_greeting()
                initial_msg = f"{name}ã•ã‚“ã€{greeting}ã€‚é‚£é ˆä¹ƒã‚ã„ã§ã™ã€‚æœ¬æ—¥ã®å•è¨ºã‚’æ‹…å½“ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„è‡´ã—ã¾ã™ã€‚\n\næ—©é€Ÿã§ã™ãŒã€å½“é™¢ã¸ã®ã”æ¥é™¢ã¯åˆã‚ã¦ã§ã™ã‹ï¼Ÿ"
                st.session_state.messages.append({"role": "assistant", "content": initial_msg})
                st.rerun()

# --- 2. å•è¨ºï¼†ãƒ•ã‚©ãƒ¼ãƒ ãƒ•ã‚§ãƒ¼ã‚º ---
else:
    p_name = st.session_state.patient_data['name']
    p_dob = st.session_state.patient_data['dob']
    
    st.caption(f"æ‹…å½“ï¼šé‚£é ˆä¹ƒã‚¢ã‚¤ | æ‚£è€…ï¼š{p_name} æ§˜ ({p_dob})")
    
    if st.button("è¨ºå¯Ÿçµ‚äº† / æ¬¡ã®æ‚£è€…ã¸"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

    for msg in st.session_state.messages:
        if msg["role"] == "assistant":
            with st.chat_message("assistant", avatar="ğŸ‘©â€âš•ï¸"):
                if "<END_OF_INTERVIEW>" in msg["content"]:
                    st.write("ï¼ˆå•è¨ºçµ‚äº†ã€‚ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒ ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰")
                elif "â–  S (Subjective)" in msg["content"]:
                     c1, c2 = st.columns([3, 1])
                     with c1: st.markdown(msg["content"])
                     with c2: st.image(generate_qr_image(msg["content"]), caption="ã‚«ãƒ«ãƒ†è»¢é€ç”¨QR")
                else:
                    st.markdown(msg["content"])
        else:
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.markdown(msg["content"])

    is_chatting = st.session_state.interview_state == "chat"

    if is_chatting:
        audio_val = st.audio_input("ãƒã‚¤ã‚¯", key=f"aud_{st.session_state.audio_key}")
        text_val = st.chat_input("å›ç­”ã‚’å…¥åŠ›")
        user_input = None

        if audio_val:
            with st.spinner("èªè­˜ä¸­..."):
                tmp = f"tmp_{int(time.time())}.wav"
                with open(tmp, "wb") as f: f.write(audio_val.getvalue())
                try: user_input = transcribe_audio_with_fallback(tmp)
                except: pass
                if os.path.exists(tmp): os.remove(tmp)
                st.session_state.audio_key += 1
        elif text_val:
            user_input = text_val

        if user_input:
            st.session_state.messages.append({"role": "user", "content": user_input})
            st.rerun()

        if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
            with st.spinner("æ€è€ƒä¸­..."):
                ai_res = generate_chat_response(st.session_state.messages, p_name, p_dob)
                if "<END_OF_INTERVIEW>" in ai_res:
                    st.session_state.interview_state = "form"
                    st.session_state.messages.append({"role": "assistant", "content": "<END_OF_INTERVIEW>"})
                else:
                    st.session_state.messages.append({"role": "assistant", "content": ai_res})
                st.rerun()

    else:
        # --- 3. ãƒ•ã‚©ãƒ¼ãƒ å…¥åŠ›ãƒ•ã‚§ãƒ¼ã‚º (ã“ã“ã‚’å¤§å¹…æ”¹è‰¯ï¼) ---
        if st.session_state.interview_state == "form":
            st.divider()
            st.subheader("ğŸ“‹ æœ€çµ‚ç¢ºèª")
            
            with st.form("final_options"):
                st.markdown("ä»¥ä¸‹ã®é …ç›®ã‚’é¸æŠã—ã¦ã€ã‚«ãƒ«ãƒ†ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
                
                # --- ç”»åƒæ¤œæŸ» ---
                st.markdown("#### ç”»åƒæ¤œæŸ»")
                img_opt = st.radio(
                    "CTã‚„MRIã§ã®è©³ã—ã„æ¤œæŸ»ã‚’å¸Œæœ›ã•ã‚Œã¾ã™ã‹ï¼Ÿ", 
                    ["ç©æ¥µçš„ã«æ¤œæŸ»ã‚’å—ã‘ãŸã„", "åŒ»å¸«ãŒå¿…è¦ã¨åˆ¤æ–­ã™ã‚Œã°æ¤œæŸ»ã‚’å—ã‘ãŸã„", "ãã‚ã—ã„æ¤œæŸ»ã¯ã„ã¾ã®ã¨ã“ã‚å¸Œæœ›ã—ãªã„"]
                )
                st.caption("â€»å½“æ—¥ã®äºˆç´„çŠ¶æ³ã«ã‚ˆã‚Šã€æœ¬æ—¥ä¸­ã«æ¤œæŸ»ãŒå—ã‘ã‚‰ã‚Œãªã„å ´åˆã‚‚ã”ã–ã„ã¾ã™ã€‚ã‚ã‚‰ã‹ã˜ã‚ã”äº†æ‰¿ãã ã•ã„ã€‚")
                st.divider()

                # --- éª¨ç²—é¬†ç—‡æ¤œæŸ» ---
                st.markdown("#### éª¨ç²—é¬†ç—‡æ¤œæŸ»")
                st.info("ğŸ’¡ 60ä»£ä»¥é™ã®å¥³æ€§ã®æ–¹ã¯ã€ä¸€åº¦éª¨ç²—é¬†ç—‡ã®æ¤œæŸ»ã‚’è¡Œã†ã“ã¨ã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€‚")
                osteo_opt = st.radio(
                    "éª¨ç²—é¬†ç—‡ã®æ¤œæŸ»ã‚’ã”å¸Œæœ›ã•ã‚Œã¾ã™ã‹ï¼Ÿ", 
                    ["ã¯ã„", "ã„ã„ãˆ"],
                    horizontal=True
                )
                st.divider()
                
                # --- åŒ»å¸«å¸Œæœ› ---
                st.markdown("#### åŒ»å¸«å¸Œæœ›")
                doc_cat = st.radio(
                    "æœ¬æ—¥ã®è¨ºå¯Ÿã‚’æ‹…å½“ã™ã‚‹åŒ»å¸«ã«ã”å¸Œæœ›ã®åŒ»å¸«ã¯ã”ã–ã„ã¾ã™ã‹ï¼Ÿ",
                    ["æ‰‹ã®å°‚é–€åŒ»", "è†ã®å°‚é–€åŒ»", "è¶³é–¢ç¯€ã€è¶³éƒ¨ï¼ˆè†ã‹ã‚‰ä¸‹ï¼‰ã®å°‚é–€åŒ»", "ç‰¹ã«å¸Œæœ›ã¯ãªã„", "åŒ»å¸«åã‚’æŒ‡å®šã™ã‚‹"]
                )
                
                # åå‰æŒ‡å®šã®å ´åˆã®å…¥åŠ›æ¬„
                doc_name_input = st.text_input("åŒ»å¸«åï¼ˆâ€»ä¸Šè¨˜ã§ã€ŒåŒ»å¸«åã‚’æŒ‡å®šã™ã‚‹ã€ã‚’é¸æŠã—ãŸå ´åˆã®ã¿è¨˜å…¥ï¼‰")
                
                st.divider()
                
                if st.form_submit_button("âœ… ã‚«ãƒ«ãƒ†ä½œæˆ"):
                    # åŒ»å¸«åã®ãƒ­ã‚¸ãƒƒã‚¯å‡¦ç†
                    if doc_cat == "åŒ»å¸«åã‚’æŒ‡å®šã™ã‚‹" and doc_name_input:
                        final_doc = f"æŒ‡å®šã‚ã‚Š: {doc_name_input}"
                    elif doc_cat == "åŒ»å¸«åã‚’æŒ‡å®šã™ã‚‹":
                        final_doc = "æŒ‡å®šã‚ã‚Š (åå‰æœªè¨˜å…¥)"
                    else:
                        final_doc = doc_cat

                    selections = {
                        "image_exam": img_opt,
                        "osteo_exam": osteo_opt,
                        "doctor": final_doc
                    }
                    
                    with st.spinner("SOAPã‚’ä½œæˆä¸­..."):
                        final_soap = generate_final_soap(st.session_state.messages, p_name, p_dob, selections)
                        
                    st.session_state.messages.append({"role": "assistant", "content": final_soap})
                    st.session_state.interview_state = "complete" 
                    st.rerun()

